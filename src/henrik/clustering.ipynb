{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.discriminant_analysis import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_full = pd.read_parquet(\"/home/henrik/projects/cedas2025/src/data/cedas2025_material/data/chargecurves_train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data_full) / 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_full.loc[train_data_full['id'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_dataframe(df):\n",
    "    first_timestamps = df.groupby('id')['timestamp'].first().reset_index()\n",
    "\n",
    "    pivot_df = df.pivot(index=['id', 'nominal_power', 'location_id'],\n",
    "                        columns='sub_id',\n",
    "                        values=['soc', 'power']).reset_index()\n",
    "\n",
    "    pivot_df.columns = [\n",
    "        f'{col[0]}_{col[1]}' if col[1] != '' else col[0]\n",
    "        for col in pivot_df.columns\n",
    "    ]\n",
    "\n",
    "    result_df = pivot_df.merge(first_timestamps, on='id')\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_full = reshape_dataframe(train_data_full)\n",
    "len(train_data_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_full = train_data_full.dropna()\n",
    "len(train_data_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = train_data_full['location_id'].nunique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows where power_any is over 500\n",
    "POWER_COLOUMNS_ALL = [f'power_{i}' for i in range(40)]\n",
    "train_data_true_known = train_data_full[train_data_full[POWER_COLOUMNS_ALL].le(500).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows where soc_0 is 0\n",
    "train_data_true_known = train_data_true_known[train_data_true_known['soc_0'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data_true_known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, temp_data = train_test_split(train_data_true_known,\n",
    "                                         train_size=0.70,\n",
    "                                         test_size=0.30,\n",
    "                                         shuffle=True,\n",
    "                                         random_state=RANDOM_STATE)\n",
    "validation_data, test_data = train_test_split(temp_data,\n",
    "                                              train_size=0.5,\n",
    "                                              test_size=0.5,\n",
    "                                              random_state=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['month'] = train_data['timestamp'].dt.month\n",
    "validation_data['month'] = validation_data['timestamp'].dt.month\n",
    "test_data['month'] = test_data['timestamp'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOC_COLOUMNS_SUBSET = [f'soc_{i}' for i in range(10)]\n",
    "POWER_COLOUMNS_SUBSET = [f'power_{i}' for i in range(10)]\n",
    "\n",
    "TARGET_POWER = [f'power_{i}' for i in range(10, 40)]\n",
    "TARGET_SOC = [f'soc_{i}' for i in range(10, 40)]\n",
    "#----\n",
    "\n",
    "all_columns = train_data.columns.tolist()\n",
    "\n",
    "REMOVE = [\"timestamp\"]\n",
    "TO_DROP_FROM_X = TARGET_POWER + TARGET_SOC + REMOVE\n",
    "\n",
    "# Define input features by excluding the target columns\n",
    "INPUT_FEATURES_CLUSTERING = [col for col in all_columns if col not in TO_DROP_FROM_X ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY FIRST 10\n",
    "train_data_first_ten = train_data[INPUT_FEATURES_CLUSTERING]\n",
    "validation_data_first_ten = validation_data[INPUT_FEATURES_CLUSTERING]\n",
    "test_data_first_ten = test_data[INPUT_FEATURES_CLUSTERING]\n",
    "\n",
    "# train_data\n",
    "train_data = train_data.drop(\"timestamp\",axis=1)\n",
    "validation_data = validation_data.drop(\"timestamp\",axis=1)\n",
    "test_data = test_data.drop(\"timestamp\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"cluster_model\", KMeans(random_state=RANDOM_STATE, n_clusters=5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_pipeline.fit(train_data_first_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = clustering_pipeline.named_steps[\"cluster_model\"].labels_\n",
    "\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of noise points: %d\" % n_noise_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labels to one hot encode\n",
    "train_data_first_ten['cluster'] = labels\n",
    "train_data['cluster'] = labels\n",
    "\n",
    "validation_clusters = clustering_pipeline.predict(validation_data_first_ten)\n",
    "validation_data_first_ten['cluster'] = validation_clusters\n",
    "validation_data['cluster'] = validation_clusters\n",
    "\n",
    "test_clusters = clustering_pipeline.predict(test_data_first_ten)\n",
    "test_data_first_ten['cluster'] = test_clusters\n",
    "test_data['cluster'] = test_clusters\n",
    "\n",
    "# Check the unique labels\n",
    "unique_labels = set(labels.tolist() + validation_clusters.tolist() + test_clusters.tolist())\n",
    "print(\"Unique cluster labels:\", unique_labels)\n",
    "\n",
    "encoder = OneHotEncoder(drop=None, sparse_output=False)\n",
    "encoder.fit(train_data[['cluster']])\n",
    "\n",
    "def one_hot_encode_and_concat(df, encoder, column_name='cluster'):\n",
    "    one_hot_encoded_array = encoder.transform(df[[column_name]])\n",
    "\n",
    "    one_hot_encoded_df = pd.DataFrame(one_hot_encoded_array,\n",
    "                                      columns=[f'{column_name}_{int(cat)}' for cat in encoder.categories_[0]],\n",
    "                                      index=df.index)\n",
    "\n",
    "    df_with_one_hot = pd.concat([df, one_hot_encoded_df], axis=1)\n",
    "\n",
    "    return df_with_one_hot\n",
    "\n",
    "\n",
    "# Apply the helper function to all datasets\n",
    "train_data_first_ten = one_hot_encode_and_concat(train_data_first_ten, encoder)\n",
    "train_data = one_hot_encode_and_concat(train_data, encoder)\n",
    "\n",
    "validation_data_first_ten = one_hot_encode_and_concat(validation_data_first_ten, encoder)\n",
    "validation_data = one_hot_encode_and_concat(validation_data, encoder)\n",
    "\n",
    "test_data_first_ten = one_hot_encode_and_concat(test_data_first_ten, encoder)\n",
    "test_data = one_hot_encode_and_concat(test_data, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_temp_col(df):\n",
    "  df = df.copy()\n",
    "  temperature_data = {\n",
    "      'month': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "      'temperatur': [-4, -4, 0, 5, 10, 14, 17, 15, 11, 5, 1, -3]\n",
    "  }\n",
    "  temp_df = pd.DataFrame(temperature_data)\n",
    "  df = df.merge(temp_df, on='month', how='left')\n",
    "  df = df.drop(columns=['month'])\n",
    "  return df\n",
    "\n",
    "\n",
    "train_data_first_ten = add_temp_col(train_data_first_ten)\n",
    "train_data = add_temp_col(train_data)\n",
    "\n",
    "validation_data_first_ten = add_temp_col(validation_data_first_ten)\n",
    "validation_data = add_temp_col(validation_data_first_ten)\n",
    "\n",
    "test_data_first_ten = add_temp_col(test_data_first_ten)\n",
    "test_data = add_temp_col(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(train_data_first_ten)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=labels, cmap='viridis', s=50)\n",
    "plt.colorbar(label='Cluster Label')\n",
    "plt.title('KMeans Clustering Results')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean():\n",
    "    # Calculate the average SOC and Power for each cluster by taking the mean across all time steps\n",
    "    cluster_avg_soc = train_data_first_ten.groupby('cluster')[SOC_COLOUMNS_SUBSET].mean().mean(axis=1)\n",
    "    cluster_avg_power = train_data_first_ten.groupby('cluster')[POWER_COLOUMNS_SUBSET].mean().mean(axis=1)\n",
    "\n",
    "    # Create a figure with two subplots: one for SOC and one for Power\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # Bar chart for average SOC\n",
    "    axes[0].bar(cluster_avg_soc.index, cluster_avg_soc.values, color='b')\n",
    "    axes[0].set_title('Average SOC per Cluster')\n",
    "    axes[0].set_xlabel('Cluster')\n",
    "    axes[0].set_ylabel('Average SOC')\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Bar chart for average Power\n",
    "    axes[1].bar(cluster_avg_power.index, cluster_avg_power.values, color='r')\n",
    "    axes[1].set_title('Average Power per Cluster')\n",
    "    axes[1].set_xlabel('Cluster')\n",
    "    axes[1].set_ylabel('Average Power')\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    # Show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variation():\n",
    "    # Combine SOC and Power columns for plotting the boxplots\n",
    "    # First, we will stack the SOC columns and Power columns for each cluster\n",
    "\n",
    "    # Create a new DataFrame to hold SOC and Power values by cluster\n",
    "    soc_data = train_data_first_ten.melt(id_vars=['cluster'], value_vars=SOC_COLOUMNS_SUBSET, var_name='SOC_Timestep', value_name='SOC')\n",
    "    power_data = train_data_first_ten.melt(id_vars=['cluster'], value_vars=POWER_COLOUMNS_SUBSET, var_name='Power_Timestep', value_name='Power')\n",
    "\n",
    "    # Set up a figure for the boxplot\n",
    "    plt.figure(figsize=(18, 8))\n",
    "\n",
    "    # Plot the SOC variation\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.boxplot(x='cluster', y='SOC', data=soc_data, palette='Blues')\n",
    "    plt.title('SOC Variation by Cluster')\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.ylabel('SOC')\n",
    "\n",
    "    # Plot the Power variation\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(x='cluster', y='Power', data=power_data, palette='Reds')\n",
    "    plt.title('Power Variation by Cluster')\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.ylabel('Power')\n",
    "\n",
    "    # Show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean()\n",
    "plot_variation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_drop = [\"cluster\",\"month\",\"id\",\"timestamp\"]\n",
    "\n",
    "# train_data_first_ten = remove_encoded_values(train_data_first_ten, to_drop)\n",
    "# train_data = remove_encoded_values(train_data, to_drop)\n",
    "# validation_data_first_ten = remove_encoded_values(validation_data_first_ten, to_drop)\n",
    "# validation_data = remove_encoded_values(validation_data, to_drop)\n",
    "# test_data_first_ten = remove_encoded_values(test_data_first_ten, to_drop)\n",
    "# test_data = remove_encoded_values(test_data, to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "def get_model_pipeline():\n",
    "    return Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('poly', PolynomialFeatures(degree=2)),\n",
    "        # ('pca', PCA(n_components=0.50)),\n",
    "        ('regressor', MultiOutputRegressor(Ridge())),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_POWER = [f'power_{i}' for i in range(10, 40)]\n",
    "TARGET_SOC = [f'soc_{i}' for i in range(10, 40)]\n",
    "\n",
    "all_columns = train_data.columns.tolist()\n",
    "\n",
    "REMOVE = [\"cluster\",\"month\",\"id\",\"timestamp\"]\n",
    "TO_DROP_FROM_X = TARGET_POWER + TARGET_SOC + REMOVE\n",
    "\n",
    "# Define input features by excluding the target columns\n",
    "INPUT_FEATURES_MODEL = [col for col in all_columns if col not in TO_DROP_FROM_X ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[INPUT_FEATURES_MODEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_power = {}\n",
    "for label in range(0, n_clusters_):\n",
    "    one_hot_column_name = f'cluster_{label}'\n",
    "\n",
    "    train_subset = train_data[train_data[one_hot_column_name] == 1]\n",
    "\n",
    "    X_train_lin = train_subset[INPUT_FEATURES_MODEL]\n",
    "    y_train_lin_power = train_subset[TARGET_POWER]\n",
    "\n",
    "    pipeline_model = get_model_pipeline()\n",
    "    pipeline_model.fit(X_train_lin, y_train_lin_power)\n",
    "\n",
    "    models_power[label] = pipeline_model\n",
    "    print(f\"Trained model for cluster {label} on {len(train_subset)} samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores_power = {}\n",
    "for cluster, model in models_power.items():\n",
    "    one_hot_column_name = f'cluster_{label}'\n",
    "    val_subset = validation_data[validation_data[one_hot_column_name] == 1]\n",
    "\n",
    "    X_val = val_subset[INPUT_FEATURES_MODEL]\n",
    "    y_val = val_subset[TARGET_POWER]\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "    validation_scores_power[cluster] = mae\n",
    "\n",
    "    print(f\"Cluster {cluster}: MAE = {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = list(validation_scores_power.keys())\n",
    "mae_values = list(validation_scores_power.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(clusters, mae_values, color='skyblue', edgecolor='black')\n",
    "plt.xlabel(\"Cluster\", fontsize=14)\n",
    "plt.ylabel(\"Mean Absolute Error (MAE)\", fontsize=14)\n",
    "plt.title(\"Validation MAE by Cluster\", fontsize=16)\n",
    "plt.xticks(clusters)\n",
    "\n",
    "for idx, mae in zip(clusters, mae_values):\n",
    "    plt.text(idx, mae + 0.2, f\"{mae:.2f}\", ha=\"center\", va=\"bottom\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_instances = len(validation_data)\n",
    "weighted_sum = 0\n",
    "\n",
    "for cluster, mae in validation_scores_power.items():\n",
    "    one_hot_column_name = f'cluster_{cluster}'\n",
    "    count = len(validation_data[validation_data[one_hot_column_name] == 1])\n",
    "    weighted_sum += mae * count\n",
    "    print(f\"Cluster {cluster}: instances = {count}, MAE = {mae:.3f}\")\n",
    "\n",
    "weighted_avg_mae = weighted_sum / total_instances\n",
    "print(f\"\\nTotal instances in validation data: {total_instances}\")\n",
    "print(f\"Weighted Average MAE POWER: {weighted_avg_mae:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOC IS NEXT\n",
    "TARGET_SOC = [f'soc_{i}' for i in range(10, 40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_soc = {}\n",
    "for label in range(0, n_clusters_):\n",
    "    one_hot_column_name = f'cluster_{label}'\n",
    "    train_subset = train_data[train_data[one_hot_column_name] == 1]\n",
    "\n",
    "    X_train_lin = train_subset[INPUT_FEATURES_MODEL]\n",
    "    y_train_lin_power = train_subset[TARGET_SOC]\n",
    "\n",
    "    pipeline_model = get_model_pipeline()\n",
    "    pipeline_model.fit(X_train_lin, y_train_lin_power)\n",
    "\n",
    "    models_soc[label] = pipeline_model\n",
    "    print(f\"Trained model for cluster {label} on {len(train_subset)} samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores_soc = {}\n",
    "for cluster, model in models_soc.items():\n",
    "    one_hot_column_name = f'cluster_{label}'\n",
    "    val_subset = validation_data[validation_data[one_hot_column_name] == 1]\n",
    "\n",
    "    X_val = val_subset[INPUT_FEATURES_MODEL]\n",
    "    y_val = val_subset[TARGET_SOC]\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "    validation_scores_soc[cluster] = mae\n",
    "\n",
    "    print(f\"Cluster {cluster}: MAE = {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster, model in models_soc.items():\n",
    "    one_hot_column_name = f'cluster_{label}'\n",
    "    val_subset = validation_data[validation_data[one_hot_column_name] == 1]\n",
    "    \n",
    "    X_val = val_subset[INPUT_FEATURES_MODEL]\n",
    "    y_val = val_subset[TARGET_SOC]\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "    validation_scores_soc[cluster] = mae\n",
    "\n",
    "    print(f\"Cluster {cluster}: MAE = {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = list(validation_scores_soc.keys())\n",
    "mae_values = list(validation_scores_soc.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(clusters, mae_values, color='skyblue', edgecolor='black')\n",
    "plt.xlabel(\"Cluster\", fontsize=14)\n",
    "plt.ylabel(\"Mean Absolute Error (MAE)\", fontsize=14)\n",
    "plt.title(\"Validation MAE by Cluster\", fontsize=16)\n",
    "plt.xticks(clusters)\n",
    "\n",
    "for idx, mae in zip(clusters, mae_values):\n",
    "    plt.text(idx, mae + 0.2, f\"{mae:.2f}\", ha=\"center\", va=\"bottom\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_instances = len(validation_data)\n",
    "weighted_sum = 0\n",
    "\n",
    "for cluster, mae in validation_scores_soc.items():\n",
    "    one_hot_column_name = f'cluster_{cluster}'\n",
    "    count = len(validation_data[validation_data[one_hot_column_name] == 1])\n",
    "    weighted_sum += mae * count\n",
    "    print(f\"Cluster {cluster}: instances = {count}, MAE = {mae:.3f}\")\n",
    "\n",
    "weighted_avg_mae = weighted_sum / total_instances\n",
    "print(f\"\\nTotal instances in validation data: {total_instances}\")\n",
    "print(f\"Weighted Average MAE SOC: {weighted_avg_mae:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedas2025-D-Y6KMbq-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
