{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>soc</th>\n",
       "      <th>power</th>\n",
       "      <th>nominal_power</th>\n",
       "      <th>location_id</th>\n",
       "      <th>sub_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-15 09:46:44</td>\n",
       "      <td>42.0</td>\n",
       "      <td>37.73</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-15 09:47:44</td>\n",
       "      <td>44.0</td>\n",
       "      <td>30.10</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-15 09:48:44</td>\n",
       "      <td>46.0</td>\n",
       "      <td>27.46</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-15 09:49:44</td>\n",
       "      <td>49.0</td>\n",
       "      <td>26.42</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-15 09:50:44</td>\n",
       "      <td>51.0</td>\n",
       "      <td>25.46</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-15 09:51:44</td>\n",
       "      <td>53.0</td>\n",
       "      <td>23.55</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-15 09:52:44</td>\n",
       "      <td>55.0</td>\n",
       "      <td>23.63</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-15 09:53:44</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22.46</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-15 09:54:44</td>\n",
       "      <td>58.0</td>\n",
       "      <td>20.93</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-15 09:55:44</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.18</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-15 09:56:44</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.99</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-15 09:57:44</td>\n",
       "      <td>62.0</td>\n",
       "      <td>19.06</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-15 09:58:44</td>\n",
       "      <td>64.0</td>\n",
       "      <td>18.29</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-15 09:59:44</td>\n",
       "      <td>65.0</td>\n",
       "      <td>17.54</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-15 10:00:44</td>\n",
       "      <td>66.0</td>\n",
       "      <td>17.21</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-15 10:01:44</td>\n",
       "      <td>68.0</td>\n",
       "      <td>16.41</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-15 10:02:44</td>\n",
       "      <td>69.0</td>\n",
       "      <td>16.04</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-15 10:03:44</td>\n",
       "      <td>70.0</td>\n",
       "      <td>15.67</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-15 10:04:44</td>\n",
       "      <td>71.0</td>\n",
       "      <td>14.90</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-15 10:05:44</td>\n",
       "      <td>72.0</td>\n",
       "      <td>14.52</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id           timestamp   soc  power  nominal_power  location_id  sub_id\n",
       "0    1 2023-03-15 09:46:44  42.0  37.73           62.5            0       0\n",
       "1    1 2023-03-15 09:47:44  44.0  30.10           62.5            0       1\n",
       "2    1 2023-03-15 09:48:44  46.0  27.46           62.5            0       2\n",
       "3    1 2023-03-15 09:49:44  49.0  26.42           62.5            0       3\n",
       "4    1 2023-03-15 09:50:44  51.0  25.46           62.5            0       4\n",
       "5    1 2023-03-15 09:51:44  53.0  23.55           62.5            0       5\n",
       "6    1 2023-03-15 09:52:44  55.0  23.63           62.5            0       6\n",
       "7    1 2023-03-15 09:53:44  56.0  22.46           62.5            0       7\n",
       "8    1 2023-03-15 09:54:44  58.0  20.93           62.5            0       8\n",
       "9    1 2023-03-15 09:55:44  60.0  20.18           62.5            0       9\n",
       "10   1 2023-03-15 09:56:44  61.0  18.99           62.5            0      10\n",
       "11   1 2023-03-15 09:57:44  62.0  19.06           62.5            0      11\n",
       "12   1 2023-03-15 09:58:44  64.0  18.29           62.5            0      12\n",
       "13   1 2023-03-15 09:59:44  65.0  17.54           62.5            0      13\n",
       "14   1 2023-03-15 10:00:44  66.0  17.21           62.5            0      14\n",
       "15   1 2023-03-15 10:01:44  68.0  16.41           62.5            0      15\n",
       "16   1 2023-03-15 10:02:44  69.0  16.04           62.5            0      16\n",
       "17   1 2023-03-15 10:03:44  70.0  15.67           62.5            0      17\n",
       "18   1 2023-03-15 10:04:44  71.0  14.90           62.5            0      18\n",
       "19   1 2023-03-15 10:05:44  72.0  14.52           62.5            0      19"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pq.read_table(source=\"../data/chargecurves_train.parquet\").to_pandas()\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "timestamp           0\n",
       "soc              6081\n",
       "power            7127\n",
       "nominal_power       0\n",
       "location_id         0\n",
       "sub_id              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>soc</th>\n",
       "      <th>power</th>\n",
       "      <th>nominal_power</th>\n",
       "      <th>location_id</th>\n",
       "      <th>sub_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.960349e+06</td>\n",
       "      <td>3960349</td>\n",
       "      <td>3.954268e+06</td>\n",
       "      <td>3.953222e+06</td>\n",
       "      <td>3.960349e+06</td>\n",
       "      <td>3.960349e+06</td>\n",
       "      <td>3.960349e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.987936e+04</td>\n",
       "      <td>2023-06-20 17:26:36.712216832</td>\n",
       "      <td>5.714675e+01</td>\n",
       "      <td>4.685585e+01</td>\n",
       "      <td>1.633075e+02</td>\n",
       "      <td>8.677634e+01</td>\n",
       "      <td>1.945163e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2022-01-01 02:42:08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.497300e+04</td>\n",
       "      <td>2022-12-13 13:28:22</td>\n",
       "      <td>4.200000e+01</td>\n",
       "      <td>2.864000e+01</td>\n",
       "      <td>6.250000e+01</td>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>9.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.984200e+04</td>\n",
       "      <td>2023-08-01 12:08:28</td>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>4.452000e+01</td>\n",
       "      <td>1.700000e+02</td>\n",
       "      <td>7.100000e+01</td>\n",
       "      <td>1.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.048190e+05</td>\n",
       "      <td>2024-01-17 15:48:11</td>\n",
       "      <td>7.300000e+01</td>\n",
       "      <td>5.944000e+01</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>1.290000e+02</td>\n",
       "      <td>2.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.400000e+05</td>\n",
       "      <td>2024-06-26 15:22:57</td>\n",
       "      <td>1.040000e+02</td>\n",
       "      <td>2.355480e+03</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>3.450000e+02</td>\n",
       "      <td>3.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.039902e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.049384e+01</td>\n",
       "      <td>2.638718e+01</td>\n",
       "      <td>9.091005e+01</td>\n",
       "      <td>7.068857e+01</td>\n",
       "      <td>1.154053e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                      timestamp           soc  \\\n",
       "count  3.960349e+06                        3960349  3.954268e+06   \n",
       "mean   6.987936e+04  2023-06-20 17:26:36.712216832  5.714675e+01   \n",
       "min    1.000000e+00            2022-01-01 02:42:08  1.000000e+00   \n",
       "25%    3.497300e+04            2022-12-13 13:28:22  4.200000e+01   \n",
       "50%    6.984200e+04            2023-08-01 12:08:28  5.800000e+01   \n",
       "75%    1.048190e+05            2024-01-17 15:48:11  7.300000e+01   \n",
       "max    1.400000e+05            2024-06-26 15:22:57  1.040000e+02   \n",
       "std    4.039902e+04                            NaN  2.049384e+01   \n",
       "\n",
       "              power  nominal_power   location_id        sub_id  \n",
       "count  3.953222e+06   3.960349e+06  3.960349e+06  3.960349e+06  \n",
       "mean   4.685585e+01   1.633075e+02  8.677634e+01  1.945163e+01  \n",
       "min    0.000000e+00   5.000000e+01  0.000000e+00  0.000000e+00  \n",
       "25%    2.864000e+01   6.250000e+01  2.800000e+01  9.000000e+00  \n",
       "50%    4.452000e+01   1.700000e+02  7.100000e+01  1.900000e+01  \n",
       "75%    5.944000e+01   2.000000e+02  1.290000e+02  2.900000e+01  \n",
       "max    2.355480e+03   5.000000e+02  3.450000e+02  3.900000e+01  \n",
       "std    2.638718e+01   9.091005e+01  7.068857e+01  1.154053e+01  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_dataframe(df):\n",
    "    first_timestamps = df.groupby('id')['timestamp'].first().reset_index()\n",
    "\n",
    "    pivot_df = df.pivot(index=['id', 'nominal_power', 'location_id'], \n",
    "                        columns='sub_id', \n",
    "                        values=['soc', 'power']).reset_index()\n",
    "    pivot_df.columns = [\n",
    "        f'{col[0]}_{col[1]}' if col[1] != '' else col[0] \n",
    "        for col in pivot_df.columns\n",
    "    ]\n",
    "    result_df = pivot_df.merge(first_timestamps, on='id')\n",
    "\n",
    "    return result_df\n",
    "\n",
    "df = reshape_dataframe(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'startswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11160\\2455636767.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Assuming df is your DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Calculate the number of missing values in \"soc\" and \"power\" columns for each row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'missing_soc'\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'soc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'missing_power'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartwith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"power\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Create the scatter plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gedvy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         ):\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'startswith'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Calculate the number of missing values in \"soc\" and \"power\" columns for each row\n",
    "\n",
    "df['missing_soc']  = df.startswith('soc').isnull().sum(axis=1)\n",
    "df['missing_power'] = df.startwith(\"power\").isnull().sum(axis=1)\n",
    "\n",
    "# Create the scatter plot\n",
    "fig = px.density_contour(\n",
    "    df, \n",
    "    x='missing_soc', \n",
    "    y='missing_power', \n",
    "    title='Missing Values in SOC vs Power Columns',\n",
    "    labels={\n",
    "        'missing_soc': 'Number of Missing SOC Values',\n",
    "        'missing_power': 'Number of Missing Power Values'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Update layout for better readability\n",
    "fig.update_layout(\n",
    "    xaxis_title='Number of Missing SOC Values',\n",
    "    yaxis_title='Number of Missing Power Values',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_and_remove_missing(df):\n",
    "    df = df.copy()  # Avoid modifying the original DataFrame\n",
    "\n",
    "    # Handle 'power_1' to 'power_39' and 'soc_1' to 'soc_39'\n",
    "    for prefix in ['power', 'soc']:\n",
    "        for i in range(1, 40):  # Covers power_1 to power_39 and soc_1 to soc_39\n",
    "            column_name = f'{prefix}_{i}'\n",
    "\n",
    "            for idx in df[df[column_name].isnull()].index:\n",
    "                if 0 < idx < len(df) - 1:  # Ensure we don't go out of bounds\n",
    "                    prev_value = df.at[idx - 1, column_name] if pd.notnull(df.at[idx - 1, column_name]) else None\n",
    "                    next_value = df.at[idx + 1, column_name] if pd.notnull(df.at[idx + 1, column_name]) else None\n",
    "\n",
    "                    if prev_value is not None and next_value is not None:\n",
    "                        df.at[idx, column_name] = (prev_value + next_value) / 2\n",
    "\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fill_and_remove_missing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(\"id\")\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)\n",
    "# 99039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a condition to check if any power value exceeds the nominal_power for each row\n",
    "condition = df[[f'power_{i}' for i in range(40)]].gt(df['nominal_power'] +1, axis=0).any(axis=1)\n",
    "\n",
    "# Filter the rows where at least one power value is greater than nominal_power\n",
    "df_filtered = df[condition]\n",
    "\n",
    "# Count the occurrences of each location_id in the filtered DataFrame\n",
    "location_counts = df_filtered['location_id'].value_counts()\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=location_counts.index, y=location_counts.values, palette='viridis')\n",
    "plt.title('Count of location IDs with inconsistencies between power and nominal power', fontsize=16)\n",
    "plt.xlabel('Location ID', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# for col in [f'power_{i}' for i in range(40)]:\n",
    "#     df[col] = df[col].clip(upper = df[\"nominal_power\"])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_temp_col(df):\n",
    "  df = df.copy()\n",
    "  temperature_data = {\n",
    "      'month': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "      'temperatur': [-4, -4, 0, 5, 10, 14, 17, 15, 11, 5, 1, -3]\n",
    "  }\n",
    "  temp_df = pd.DataFrame(temperature_data)\n",
    "  df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "  df['month'] = df['timestamp'].dt.month\n",
    "  df = df.merge(temp_df, on='month', how='left')\n",
    "  df = df.drop(columns=['month'])\n",
    "  return df\n",
    "\n",
    "df = add_temp_col(df)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extract the month from the timestamp\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "df['month'] = df['timestamp'].dt.month  # Extract month from timestamp\n",
    "\n",
    "# 2. Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')  # drop='first' avoids the dummy variable trap\n",
    "\n",
    "# 3. Reshape the data (encoder requires 2D array)\n",
    "month_values = df['month'].values.reshape(-1, 1)\n",
    "\n",
    "# 4. Fit and transform the data\n",
    "encoded_months = encoder.fit_transform(month_values)\n",
    "\n",
    "# 5. Create column names for the encoded months\n",
    "encoded_columns = [f'month_{int(i)}' for i in encoder.categories_[0][1:]]  # Drop first category (January)\n",
    "\n",
    "# 6. Convert the encoded months into a DataFrame\n",
    "df_encoded_months = pd.DataFrame(encoded_months, columns=encoded_columns, index=df.index)\n",
    "\n",
    "# 7. Concatenate the encoded columns to the original DataFrame\n",
    "df = pd.concat([df, df_encoded_months], axis=1)\n",
    "\n",
    "# 8. Drop the temporary 'month' column\n",
    "df = df.drop(columns=['month'])\n",
    "\n",
    "# 9. Print the updated DataFrame to verify\n",
    "print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, temp = train_test_split(df, train_size=0.70, test_size=0.30, shuffle=True, random_state=42)\n",
    "validation, test = train_test_split(temp, train_size=0.5, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train['nominal_power'], bins=10, kde=False, color='blue')\n",
    "\n",
    "plt.title('Distribution of Nominal Power')\n",
    "plt.xlabel('Nominal Power')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input features and target columns\n",
    "INPUT_FEATURES = [f'power_{i}' for i in range(10)] + [f'soc_{i}' for i in range(10)]\n",
    "INPUT_FEATURES += [\"nominal_power\",\"location_id\"] # timestamp\n",
    "# todo location_id should be discrete\n",
    "# todo add timestamp\n",
    "TARGETS = [f'power_{i}' for i in range(10, 40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "X_train = train[INPUT_FEATURES]\n",
    "y_train = train[TARGETS]\n",
    "\n",
    "# Prepare validation data\n",
    "X_val = validation[INPUT_FEATURES]\n",
    "y_val = validation[TARGETS]\n",
    "\n",
    "# Prepare test data\n",
    "X_test = test[INPUT_FEATURES]\n",
    "y_test = test[TARGETS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-output SVM\n",
    "model = MultiOutputRegressor(SVR())\n",
    "model.fit(X_train.iloc[:10000], y_train.iloc[:10000])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred = model.predict(X_val[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_validation = mean_absolute_error(y_pred, y_val[:10000])\n",
    "\n",
    "print(f'Validation MAE: {mae_validation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "X_train_sample = X_train.sample(frac=0.1, random_state=42)\n",
    "y_train_sample = y_train.sample(frac=0.1, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Apply PCA for dimensionality reduction (optional, based on your needs)\n",
    "pca = PCA(n_components=5)  # Reduce to 5 components (adjust as needed)\n",
    "\n",
    "\n",
    "\n",
    "# Transform the input features\n",
    "X_transformed = pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('loc', OneHotEncoder(), ['location_id']),  # One-hot encode location_id\n",
    "        ('num', StandardScaler(), [col for col in INPUT_FEATURES if col != 'location_id'])  # Standardize numerical features\n",
    "    ])\n",
    "\n",
    "# Apply preprocessing to training, validation, and test data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_val_preprocessed = preprocessor.transform(X_val)  # No fitting, just transform\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df['hour'] = df['timestamp'].dt.hour\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.histplot(df, x='hour', weights='total_power', bins=24, kde=True)\n",
    "\n",
    "# # Customize plot\n",
    "# plt.xlabel(\"Hour of the Day\")\n",
    "# plt.ylabel(\"Total Power Consumption\")\n",
    "# plt.title(\"Total Power Consumption at Different Times of the Day\")\n",
    "# plt.xticks(range(0, 24))  # Ensure all hours are labeled\n",
    "# plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# # Show plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the weekday (0 = Monday, 6 = Sunday)\n",
    "# df['weekday'] = df['timestamp'].dt.dayofweek\n",
    "\n",
    "# # Map weekdays to names\n",
    "# weekday_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "# df['weekday_name'] = df['weekday'].map(lambda x: weekday_names[x])\n",
    "\n",
    "# # Aggregate total power consumption per weekday\n",
    "# weekday_power = df.groupby('weekday_name')['total_power'].sum().reindex(weekday_names)  # Ensure correct order\n",
    "\n",
    "# # Plot\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# sns.barplot(x=weekday_power.index, y=weekday_power.values, palette='viridis')\n",
    "\n",
    "# # Customize\n",
    "# plt.xlabel(\"Day of the Week\")\n",
    "# plt.ylabel(\"Total Power Consumption\")\n",
    "# plt.title(\"Total Power Consumption by Weekday\")\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# # Show plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
